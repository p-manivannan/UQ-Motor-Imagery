{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9515290a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "# Set notebook to use only one GPU\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce008765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 13:11:08.651228: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-24 13:11:08.671625: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-24 13:11:08.671643: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-24 13:11:08.671661: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-24 13:11:08.675949: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not install, you could not use those pipelines\n",
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 13:11:09.106803: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Keras Uncertainty will use standalone Keras backend"
     ]
    }
   ],
   "source": [
    "from braindecode.datasets.moabb import MOABBDataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from braindecode.preprocessing import create_windows_from_events\n",
    "from braindecode.preprocessing import (\n",
    "    exponential_moving_standardize, preprocess, Preprocessor)\n",
    "from numpy import multiply\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from models_bachelors import *\n",
    "from file_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b315848",
   "metadata": {},
   "source": [
    "# Preprocessing functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550ef50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    dataset = MOABBDataset(dataset_name=\"BNCI2014001\", subject_ids=None)\n",
    "    return dataset\n",
    "\n",
    "def preprocess_data(dataset):\n",
    "    # Parameters for exponential moving standardization\n",
    "    factor_new = 1e-3\n",
    "    init_block_size = 1000\n",
    "    # Factor to convert from V to mV\n",
    "    factor = 1e6\n",
    "\n",
    "    preprocessors = [\n",
    "        Preprocessor('pick_types', eeg=True, meg=False, stim=False),  # Keep EEG sensors\n",
    "        Preprocessor(lambda data: multiply(data, factor)),  # Convert from V to uV\n",
    "        Preprocessor(exponential_moving_standardize,  # Exponential moving standardization\n",
    "                    factor_new=factor_new, init_block_size=init_block_size)\n",
    "    ]\n",
    "\n",
    "    return preprocess(dataset, preprocessors)\n",
    "\n",
    "def epoch_data(dataset):\n",
    "    trial_start_offset_seconds = -0.5\n",
    "    # Extract sampling frequency, check that they are same in all datasets\n",
    "    sfreq = dataset.datasets[0].raw.info['sfreq']\n",
    "    assert all([ds.raw.info['sfreq'] == sfreq for ds in dataset.datasets])\n",
    "    # Calculate the trial start offset in samples.\n",
    "    trial_start_offset_samples = int(trial_start_offset_seconds * sfreq)\n",
    "\n",
    "    # Create windows using braindecode function for this. It needs parameters to\n",
    "    # define how trials should be used.\n",
    "    windows_dataset = create_windows_from_events(\n",
    "        dataset,\n",
    "        trial_start_offset_samples=trial_start_offset_samples,\n",
    "        trial_stop_offset_samples=0,\n",
    "        preload=True,\n",
    "    )\n",
    "\n",
    "    return windows_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca37b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expects a BaseConcatDataset object\n",
    "# Iterate through subject datasets and create dataset of 9 rows and 576 columns\n",
    "# (9 subjects and 576 trials).\n",
    "def create_dataframe_helper(dataset):\n",
    "    subjects_lst = []\n",
    "    subjects_targets = []\n",
    "    for subject_id in range(0, len(dataset)):\n",
    "        # Append to list a set of inputs and targets from each run\n",
    "        # in subject dataset\n",
    "        inputs = []\n",
    "        targets = []\n",
    "        subject_dataset = dataset[subject_id].datasets\n",
    "        for run in subject_dataset:\n",
    "            for trial in run:\n",
    "                inputs.append(trial[0])\n",
    "                targets.append(trial[1])\n",
    "        subjects_lst.append(inputs)\n",
    "        subjects_targets.append(targets)\n",
    "\n",
    "    return np.asarray(subjects_lst), np.asarray(subjects_targets)\n",
    "\n",
    "\n",
    "def create_dataframe(processed_data):\n",
    "    # Data to be saved gonna have shape (9, 576, 22, 1125)\n",
    "    # 9 subjects. 576 trials each. 22 channels. 1125 timestamps\n",
    "    split_data = processed_data.split('subject')\n",
    "    split_data = [split_data[str(i)] for i in range(1, 9 + 1)]\n",
    "    inputs, targets = create_dataframe_helper(split_data)\n",
    "    return inputs, targets\n",
    "\n",
    "def onehot(targets):\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    targets = targets.reshape(-1,1)\n",
    "    targets = encoder.fit_transform(targets)\n",
    "    n_subj = 9\n",
    "    n_trials = 576\n",
    "    n_classes = 4\n",
    "    targets = targets.reshape(n_subj, n_trials, n_classes)\n",
    "    return targets\n",
    "    \n",
    "\n",
    "def get_x_y(inputs, targets):\n",
    "    n_runs = inputs.shape[1] * inputs.shape[0]\n",
    "    channels = inputs.shape[2]\n",
    "    timestamps = inputs.shape[3]\n",
    "    n_classes = targets.shape[2]\n",
    "    X = np.vstack(inputs).reshape(n_runs, channels, timestamps)\n",
    "    Y = np.vstack(targets).reshape(n_runs, n_classes)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32d19d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "48 events found\n",
      "Event IDs: [1 2 3 4]\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmanivannan/miniconda3/envs/tf/lib/python3.9/site-packages/braindecode/preprocessing/preprocess.py:55: UserWarning: Preprocessing choices with lambda functions cannot be saved.\n",
      "  warn('Preprocessing choices with lambda functions cannot be saved.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n",
      "Used Annotations descriptions: ['feet', 'left_hand', 'right_hand', 'tongue']\n"
     ]
    }
   ],
   "source": [
    "pre_processed_data = preprocess_data(load_dataset())\n",
    "processed_data = epoch_data(pre_processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "469f25e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pmanivannan/miniconda3/envs/tf/lib/python3.9/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 576, 22, 1125) (9, 576, 4)\n"
     ]
    }
   ],
   "source": [
    "inputs, targets = create_dataframe(processed_data)\n",
    "targets = onehot(targets)\n",
    "print(inputs.shape, targets.shape)\n",
    "save_dict_to_hdf5({'inputs': inputs, 'targets': targets}, 'dataset') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae90ceb0",
   "metadata": {},
   "source": [
    "# Lockbox Creation\n",
    "\n",
    "Instead of saving a separate file containing the data of the lockboxed set, the lockbox file contains the indices of the to-be lockboxed set for each test subject. \n",
    "\n",
    "This way, the lockbox trials can be easily excluded during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b0f3d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_bachelors import *\n",
    "from file_functions import *\n",
    "from numpy.random import default_rng\n",
    "from sklearn.model_selection import KFold\n",
    "loaded_inputs = inputs\n",
    "loaded_targets = targets\n",
    "\n",
    "# Create Lockbox for each subject\n",
    "n_s = 9  # Number of subjects\n",
    "\n",
    "'''\n",
    "NEED TO IGNORE THE TEST SUBJECT AND LOXCKBOX THE REST!\n",
    "YOU CAN USE KFOLD SPLIT FOR THISb  \n",
    "'''\n",
    "\n",
    "kfold_lock = KFold(n_splits= n_s, shuffle= False)\n",
    "rng = default_rng()\n",
    "\n",
    "lockbox = []\n",
    "\n",
    "'''\n",
    "MIGHT BE A PROBLEM THAT IM USING KFOLD TO SPLIT LOCKBOX HERE WHILE USING ANOTHER\n",
    "METHOD TO SELECT TRAIN AND TEST IDS ELSEWHERE.\n",
    "IT WOULD BE BEST IF I MAKE THE LOCKBOX A DICT OF DICTS OF NP ARRAY OF INDEXES (57,)\n",
    "'''\n",
    "\n",
    "# Split into train and test indices. The test indices are to indicate which\n",
    "# subject to save as and the train indices are where the magic happens\n",
    "for train_idx, test_idx in kfold_lock.split(loaded_inputs, loaded_targets):\n",
    "    lockbox_idx = []\n",
    "    # Perform the lockbox operation on the train indices as follows:\n",
    "    # Take 10% of the indices from each train subject, making sure \n",
    "    # to separate them by subject and NOT concatenating.\n",
    "    # This is because the indices are dependent on the subject.\n",
    "    for idx in train_idx:\n",
    "        subject_inputs = loaded_inputs[idx]\n",
    "        num_trials= subject_inputs.shape[0]\n",
    "        # Get random 10% of subject's trials\n",
    "        indexes = rng.choice(num_trials, size=int(0.1 * num_trials), replace=False)\n",
    "        lockbox_idx.append(indexes)\n",
    "\n",
    "    # This operation assumes index of lockbox corresponds to test_idx\n",
    "    lockbox.append(lockbox_idx)\n",
    "    \n",
    "\n",
    "lockbox = np.array(lockbox)\n",
    "save_dict_to_hdf5(dict({'data': lockbox}), 'lockbox')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
