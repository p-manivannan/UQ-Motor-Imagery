{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "# Set notebook to use only one GPU\n",
    "%env CUDA_VISIBLE_DEVICES=1     \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 12:18:54.487672: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-09 12:18:54.507681: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-09 12:18:54.507697: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-09 12:18:54.507714: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-09 12:18:54.512181: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 12:18:54.892447: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keras Uncertainty will use standalone Keras backend"
     ]
    }
   ],
   "source": [
    "import file_functions as ff\n",
    "import numpy as np\n",
    "methods = ff.fetch_method_names()\n",
    "per_subj_dict = ff.create_per_subj_dict()\n",
    "metrics = ff.fetch_metric_names()\n",
    "keys = ff.fetch_keys()      # Fetches names names for within-pop and out-of-pop sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Per-subject uncertainties and AUROC\n",
    "This is exactly what I need:\n",
    "    - Per subject AUROC. This can only be done with array of shape (9, 576).\n",
    "        - start w/ (50, 9, 50, 576, 4) for a method.\n",
    "        - Mean axis=0 -> (9, 50, 576, 4)\n",
    "        - Get uncertainties -> (9, 576) -> Mean axis -1=Avg. uncertainties -> (9, 1)\n",
    "        - For each subject in axis 0, calculate AUROC to get final array of (9, 1)\n",
    "    - Array of shape (9, 1) for uncertanties\n",
    "        - Get uncertainties -> (9, 576) -> Mean axis -1=Avg. uncertainties -> (9, 1)\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.patches as mpatches\n",
    "from numpy import round\n",
    "\n",
    "'''\n",
    "Gets a numpy array down to a 2D array\n",
    "'''\n",
    "def get_in_shape(data):\n",
    "    # If data has shape of 2 elements or less, assume it's already in shape\n",
    "    if len(data.shape) < 3:\n",
    "        return data\n",
    "    else:\n",
    "        while len(data.shape) > 2:\n",
    "            data = np.vstack(data)\n",
    "        return data\n",
    "\n",
    "'''\n",
    "data can be whatever shape.\n",
    "manual roc plot creation reqs:\n",
    "    y_pred: (50, 576, 4)\n",
    "'''\n",
    "def get_fpr_tpr(y_true, y_pred, unc, isStandard):\n",
    "    thresholds = np.arange(0, 1.001, 0.001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    y_pred = get_in_shape(y_pred.mean(axis=0)) if isStandard not in [1, 2] else y_pred     # Take mean of axis with forward passes with methods aren't standard and DUQ\n",
    "    y_true = get_in_shape(y_true)\n",
    "\n",
    "    for t in thresholds:\n",
    "        '''\n",
    "        Order is reversed because FPR and TPR are reversed for some reason\n",
    "        '''\n",
    "        if isStandard == 2:     # For DUQ, AUROC is better when maximum distance to any class is chosen. But this flips the AUROC.\n",
    "            certains = (t > unc)\n",
    "            uncertains = (t < unc)\n",
    "        else:\n",
    "            certains = (t < unc)           # Certain when uncertainty is below threshold\n",
    "            uncertains = (t > unc)\n",
    "        # Calculate TPR and FPR\n",
    "        tp = sum(y_pred.argmax(axis=1)[uncertains] != y_true.argmax(axis=1)[uncertains])     # N. preds uncertain predictions that are incorrect\n",
    "        fn = sum(y_pred.argmax(axis=1)[certains] != y_true.argmax(axis=1)[certains])      # Prediction that's certain and incorrect\n",
    "        fp = sum(y_pred.argmax(axis=1)[uncertains] == y_true.argmax(axis=1)[uncertains])   # prediction that's uncertain and correct\n",
    "        tn = sum(y_pred.argmax(axis=1)[certains] == y_true.argmax(axis=1)[certains]) # Prediction that's certain and correct\n",
    "        # print(f'tp: {tp} fn: {fn} fp: {fp} tn: {tn}')\n",
    "        fpr.append(fp / (fp + tn))\n",
    "        tpr.append(tp / (tp + fn))\n",
    "    return np.array(tpr), np.array(fpr)\n",
    "\n",
    "def get_auroc(y_true, y_pred, unc, isStandard):\n",
    "    tpr, fpr = get_fpr_tpr(y_true, y_pred, unc, isStandard)\n",
    "    return auc(tpr, fpr)\n",
    "\n",
    "def per_subject_metrics(data, method, key, unc_method):\n",
    "    key_set = data[key]        # Whether lockbox or preds of the method\n",
    "    y_true = key_set['labels']\n",
    "    isStandard = ff.checkIfStandard(method)\n",
    "    # Average the set of 50 predictions for flipout and MC methods\n",
    "    y_preds = key_set['preds'].mean(axis=0) if 'mc' in method or 'flipout' in method else key_set['preds']\n",
    "    unc = ff.get_uncertainty(y_preds, unc_method, isStandard)\n",
    "    per_subject_aucs = []\n",
    "    for subject_id in range(y_preds.shape[0]):\n",
    "        per_subject_aucs.append(get_auroc(y_true[subject_id], y_preds[subject_id], unc[subject_id], isStandard))\n",
    "\n",
    "    return np.array(per_subject_aucs), unc.mean(axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "'''\n",
    "data: (50, 9, 50, 576, 4)\n",
    "method: 'mcdropconnect'/'mcdropout'/'standard'/'standard_dropconnect'\n",
    "key: 'test'/'lockbox'\n",
    "'''\n",
    "def do_everything(data, method, key, unc_method):\n",
    "    # data shape for UQ preds: (50, 9, 50, 576, 4)\n",
    "    aurocs, uncertainties = per_subject_metrics(data, method, key, unc_method)\n",
    "    return aurocs, uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dropconnect', 'dropout', 'duq', 'ensemble', 'flipout', 'mcdropconnect', 'mcdropout']\n",
      "dropconnect\n",
      "test\n",
      "y_preds: (9, 576); y_trues: (9, 576)\n",
      "lockbox\n",
      "y_preds: (9, 456); y_trues: (9, 456)\n",
      "dropout\n",
      "test\n",
      "y_preds: (9, 576); y_trues: (9, 576)\n",
      "lockbox\n",
      "y_preds: (9, 456); y_trues: (9, 456)\n",
      "duq\n",
      "test\n",
      "y_preds: (9, 576); y_trues: (9, 576)\n",
      "lockbox\n",
      "y_preds: (9, 456); y_trues: (9, 456)\n",
      "ensemble\n",
      "test\n",
      "y_preds: (9, 576); y_trues: (9, 576)\n",
      "lockbox\n",
      "y_preds: (9, 456); y_trues: (9, 456)\n",
      "flipout\n",
      "IN LOADING:  (9, 576, 4)\n",
      "IN LOADING:  (9, 576, 4)\n",
      "test\n",
      "y_preds: (2, 576); y_trues: (9, 576)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(key)\n\u001b[0;32m----> 8\u001b[0m         accs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_accuracies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m         per_subj_dict[method][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][key] \u001b[38;5;241m=\u001b[39m accs\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m methods:\n",
      "File \u001b[0;32m~/UQ-Motor-Imagery/file_functions/result_analysis.py:192\u001b[0m, in \u001b[0;36mget_accuracies\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Get accuracy of each subject\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, subject \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(y_trues):\n\u001b[0;32m--> 192\u001b[0m     score \u001b[38;5;241m=\u001b[39m accuracy_score(y_pred\u001b[38;5;241m=\u001b[39msubject, y_true\u001b[38;5;241m=\u001b[39m\u001b[43my_preds\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    193\u001b[0m     acc\u001b[38;5;241m.\u001b[39mappend(score)\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m acc\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "# For each method, get accuracy on test (out-of-population) \n",
    "# and lockbox (within-population) set\n",
    "print(methods)\n",
    "for method in methods:\n",
    "    preds = ff.load_predictions(method)[method]\n",
    "    for key in keys:\n",
    "        print(key)\n",
    "        accs = np.array(ff.get_accuracies(preds[key]))\n",
    "        per_subj_dict[method]['accuracy'][key] = accs\n",
    "\n",
    "for method in methods:\n",
    "    print('-----------------------------------------------')\n",
    "    print(method)\n",
    "    for key in keys:\n",
    "        print(key)\n",
    "        data = ff.load_predictions(method)[method]\n",
    "        for unc_method in metrics:\n",
    "            print(unc_method)\n",
    "            if unc_method == 'accuracy':\n",
    "                continue\n",
    "            elif unc_method == 'mutual-information' and 'standard' in method:\n",
    "                continue\n",
    "            aurocs, _ = ff.do_everything(data, method, key, unc_method)\n",
    "            per_subj_dict[method][unc_method][key] = aurocs\n",
    "            print(f'{np.mean(aurocs) * 100} +/- {np.std(aurocs) * 100}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
