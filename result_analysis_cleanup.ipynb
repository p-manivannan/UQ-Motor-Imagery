{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "# Set notebook to use only one GPU\n",
    "%env CUDA_VISIBLE_DEVICES=1     \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import file_functions as ff\n",
    "import numpy as np\n",
    "methods = ff.fetch_method_names()\n",
    "per_subj_dict = ff.create_per_subj_dict()\n",
    "metrics = ff.fetch_metric_names()\n",
    "keys = ff.fetch_keys()      # Fetches names names for within-pop and out-of-pop sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Per-subject uncertainties and AUROC\n",
    "This is exactly what I need:\n",
    "    - Per subject AUROC. This can only be done with array of shape (9, 576).\n",
    "        - start w/ (50, 9, 50, 576, 4) for a method.\n",
    "        - Mean axis=0 -> (9, 50, 576, 4)\n",
    "        - Get uncertainties -> (9, 576) -> Mean axis -1=Avg. uncertainties -> (9, 1)\n",
    "        - For each subject in axis 0, calculate AUROC to get final array of (9, 1)\n",
    "    - Array of shape (9, 1) for uncertanties\n",
    "        - Get uncertainties -> (9, 576) -> Mean axis -1=Avg. uncertainties -> (9, 1)\n",
    "'''\n",
    "\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.patches as mpatches\n",
    "from numpy import round\n",
    "\n",
    "'''\n",
    "Gets a numpy array down to a 2D array\n",
    "'''\n",
    "def get_in_shape(data):\n",
    "    # If data has shape of 2 elements or less, assume it's already in shape\n",
    "    if len(data.shape) < 3:\n",
    "        return data\n",
    "    else:\n",
    "        while len(data.shape) > 2:\n",
    "            data = np.vstack(data)\n",
    "        return data\n",
    "\n",
    "'''\n",
    "data can be whatever shape.\n",
    "manual roc plot creation reqs:\n",
    "    y_pred: (50, 576, 4)\n",
    "'''\n",
    "def get_fpr_tpr(y_true, y_pred, unc, isStandard):\n",
    "    thresholds = np.arange(0, 1.001, 0.001)\n",
    "    tpr = []\n",
    "    fpr = []\n",
    "    y_pred = get_in_shape(y_pred.mean(axis=0)) if isStandard not in [1, 2] else y_pred     # Take mean of axis with forward passes with methods aren't standard and DUQ\n",
    "    y_true = get_in_shape(y_true)\n",
    "\n",
    "    for t in thresholds:\n",
    "        '''\n",
    "        Order is reversed because FPR and TPR are reversed for some reason\n",
    "        '''\n",
    "        if isStandard == 2:     # For DUQ, AUROC is better when maximum distance to any class is chosen. But this flips the AUROC.\n",
    "            certains = (t > unc)\n",
    "            uncertains = (t < unc)\n",
    "        else:\n",
    "            certains = (t < unc)           # Certain when uncertainty is below threshold\n",
    "            uncertains = (t > unc)\n",
    "        # Calculate TPR and FPR\n",
    "        tp = sum(y_pred.argmax(axis=1)[uncertains] != y_true.argmax(axis=1)[uncertains])     # N. preds uncertain predictions that are incorrect\n",
    "        fn = sum(y_pred.argmax(axis=1)[certains] != y_true.argmax(axis=1)[certains])      # Prediction that's certain and incorrect\n",
    "        fp = sum(y_pred.argmax(axis=1)[uncertains] == y_true.argmax(axis=1)[uncertains])   # prediction that's uncertain and correct\n",
    "        tn = sum(y_pred.argmax(axis=1)[certains] == y_true.argmax(axis=1)[certains]) # Prediction that's certain and correct\n",
    "        # print(f'tp: {tp} fn: {fn} fp: {fp} tn: {tn}')\n",
    "        fpr.append(fp / (fp + tn))\n",
    "        tpr.append(tp / (tp + fn))\n",
    "    return np.array(tpr), np.array(fpr)\n",
    "\n",
    "def get_auroc(y_true, y_pred, unc, isStandard):\n",
    "    tpr, fpr = get_fpr_tpr(y_true, y_pred, unc, isStandard)\n",
    "    return auc(tpr, fpr)\n",
    "\n",
    "def per_subject_metrics(data, method, key, unc_method):\n",
    "    key_set = data[key]        # Whether lockbox or preds of the method\n",
    "    y_true = key_set['labels']\n",
    "    isStandard = ff.checkIfStandard(method)\n",
    "    # Average the set of 50 predictions for flipout and MC methods\n",
    "    y_preds = key_set['preds'].mean(axis=0) if 'mc' in method or 'flipout' in method else key_set['preds']\n",
    "    unc = ff.get_uncertainty(y_preds, unc_method, isStandard)\n",
    "    per_subject_aucs = []\n",
    "    for subject_id in range(y_preds.shape[0]):\n",
    "        per_subject_aucs.append(get_auroc(y_true[subject_id], y_preds[subject_id], unc[subject_id], isStandard))\n",
    "\n",
    "    return np.array(per_subject_aucs), unc.mean(axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "'''\n",
    "data: (50, 9, 50, 576, 4)\n",
    "method: 'mcdropconnect'/'mcdropout'/'standard'/'standard_dropconnect'\n",
    "key: 'test'/'lockbox'\n",
    "'''\n",
    "def do_everything(data, method, key, unc_method):\n",
    "    # data shape for UQ preds: (50, 9, 50, 576, 4)\n",
    "    aurocs, uncertainties = per_subject_metrics(data, method, key, unc_method)\n",
    "    return aurocs, uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'file_functions' has no attribute 'get_accuracies'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m     preds \u001b[38;5;241m=\u001b[39m ff\u001b[38;5;241m.\u001b[39mload_predictions(method)[method]\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m keys:\n\u001b[0;32m----> 7\u001b[0m         accs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_accuracies\u001b[49m(preds[key]))\n\u001b[1;32m      8\u001b[0m         per_subj_dict[method][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m][key] \u001b[38;5;241m=\u001b[39m accs\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m methods:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'file_functions' has no attribute 'get_accuracies'"
     ]
    }
   ],
   "source": [
    "# For each method, get accuracy on test (out-of-population) \n",
    "# and lockbox (within-population) set\n",
    "\n",
    "for method in methods:\n",
    "    preds = ff.load_predictions(method)[method]\n",
    "    for key in keys:\n",
    "        accs = np.array(ff.get_accuracies(preds[key]))\n",
    "        per_subj_dict[method]['accuracy'][key] = accs\n",
    "\n",
    "for method in methods:\n",
    "    print('-----------------------------------------------')\n",
    "    print(method)\n",
    "    for key in keys:\n",
    "        print(key)\n",
    "        data = ff.load_predictions(method)[method]\n",
    "        for unc_method in metrics:\n",
    "            print(unc_method)\n",
    "            if unc_method == 'accuracy':\n",
    "                continue\n",
    "            elif unc_method == 'mutual-information' and 'standard' in method:\n",
    "                continue\n",
    "            aurocs, _ = ff.do_everything(data, method, key, unc_method)\n",
    "            per_subj_dict[method][unc_method][key] = aurocs\n",
    "            print(f'{np.mean(aurocs) * 100} +/- {np.std(aurocs) * 100}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
